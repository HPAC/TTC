   __m512 _t01[16];
   _t01[0] = _mm512_unpacklo_ps(rowA0, rowA1);
   _t01[1] = _mm512_unpackhi_ps(rowA0, rowA1);
   _t01[2] = _mm512_unpacklo_ps(rowA2, rowA3);
   _t01[3] = _mm512_unpackhi_ps(rowA2, rowA3);
   _t01[4] = _mm512_unpacklo_ps(rowA4, rowA5);
   _t01[5] = _mm512_unpackhi_ps(rowA4, rowA5);
   _t01[6] = _mm512_unpacklo_ps(rowA6, rowA7);
   _t01[7] = _mm512_unpackhi_ps(rowA6, rowA7);
   _t01[8] = _mm512_unpacklo_ps(rowA8, rowA9);
   _t01[9] = _mm512_unpackhi_ps(rowA8, rowA9);
   _t01[10] = _mm512_unpacklo_ps(rowA10, rowA11);
   _t01[11] = _mm512_unpackhi_ps(rowA10, rowA11);
   _t01[12] = _mm512_unpacklo_ps(rowA12, rowA13);
   _t01[13] = _mm512_unpackhi_ps(rowA12, rowA13);
   _t01[14] = _mm512_unpacklo_ps(rowA14, rowA15);
   _t01[15] = _mm512_unpackhi_ps(rowA14, rowA15);

   rowA0 = _mm512_castpd_ps( _mm512_unpacklo_pd( _mm512_castps_pd(_t01[0]), _mm512_castps_pd(_t01[2])) );
   rowA1 = _mm512_castpd_ps( _mm512_unpackhi_pd( _mm512_castps_pd(_t01[0]), _mm512_castps_pd(_t01[2])) );
   rowA2 = _mm512_castpd_ps( _mm512_unpacklo_pd( _mm512_castps_pd(_t01[1]), _mm512_castps_pd(_t01[3])) );
   rowA3 = _mm512_castpd_ps( _mm512_unpackhi_pd( _mm512_castps_pd(_t01[1]), _mm512_castps_pd(_t01[3])) );
   rowA4 = _mm512_castpd_ps( _mm512_unpacklo_pd( _mm512_castps_pd(_t01[4]), _mm512_castps_pd(_t01[6])) );
   rowA5 = _mm512_castpd_ps( _mm512_unpackhi_pd( _mm512_castps_pd(_t01[4]), _mm512_castps_pd(_t01[6])) );
   rowA6 = _mm512_castpd_ps( _mm512_unpacklo_pd( _mm512_castps_pd(_t01[5]), _mm512_castps_pd(_t01[7])) );
   rowA7 = _mm512_castpd_ps( _mm512_unpackhi_pd( _mm512_castps_pd(_t01[5]), _mm512_castps_pd(_t01[7])) );
   rowA8 = _mm512_castpd_ps( _mm512_unpacklo_pd( _mm512_castps_pd(_t01[8]), _mm512_castps_pd(_t01[10])) );
   rowA9 = _mm512_castpd_ps( _mm512_unpackhi_pd( _mm512_castps_pd(_t01[8]), _mm512_castps_pd(_t01[10])) );
   rowA10 = _mm512_castpd_ps( _mm512_unpacklo_pd( _mm512_castps_pd(_t01[9]), _mm512_castps_pd(_t01[11])) );
   rowA11 = _mm512_castpd_ps( _mm512_unpackhi_pd( _mm512_castps_pd(_t01[9]), _mm512_castps_pd(_t01[11])) );
   rowA12 = _mm512_castpd_ps( _mm512_unpacklo_pd( _mm512_castps_pd(_t01[12]), _mm512_castps_pd(_t01[14])) );
   rowA13 = _mm512_castpd_ps( _mm512_unpackhi_pd( _mm512_castps_pd(_t01[12]), _mm512_castps_pd(_t01[14])) );
   rowA14 = _mm512_castpd_ps( _mm512_unpacklo_pd( _mm512_castps_pd(_t01[13]), _mm512_castps_pd(_t01[15])) );
   rowA15 = _mm512_castpd_ps( _mm512_unpackhi_pd( _mm512_castps_pd(_t01[13]), _mm512_castps_pd(_t01[15])) );

   _t01[0]  = _mm512_shuffle_f32x4 ((rowA0), (rowA4), 0x44);
   _t01[1]  = _mm512_shuffle_f32x4 ((rowA0), (rowA4), 0xEE);
   _t01[2]  = _mm512_shuffle_f32x4 ((rowA1), (rowA5), 0x44);
   _t01[3]  = _mm512_shuffle_f32x4 ((rowA1), (rowA5), 0xEE);
   _t01[4]  = _mm512_shuffle_f32x4 ((rowA2), (rowA6), 0x44);
   _t01[5]  = _mm512_shuffle_f32x4 ((rowA2), (rowA6), 0xEE);
   _t01[6]  = _mm512_shuffle_f32x4 ((rowA3), (rowA7), 0x44);
   _t01[7]  = _mm512_shuffle_f32x4 ((rowA3), (rowA7), 0xEE);
   _t01[8]  = _mm512_shuffle_f32x4 ((rowA8), (rowA12), 0x44);
   _t01[9]  = _mm512_shuffle_f32x4 ((rowA8), (rowA12), 0xEE);
   _t01[10] = _mm512_shuffle_f32x4 ((rowA9), (rowA13), 0x44);
   _t01[11] = _mm512_shuffle_f32x4 ((rowA9), (rowA13), 0xEE);
   _t01[12] = _mm512_shuffle_f32x4 ((rowA10), (rowA14), 0x44);
   _t01[13] = _mm512_shuffle_f32x4 ((rowA10), (rowA14), 0xEE);
   _t01[14] = _mm512_shuffle_f32x4 ((rowA11), (rowA15), 0x44);
   _t01[15] = _mm512_shuffle_f32x4 ((rowA11), (rowA15), 0xEE);

   rowA0   = _mm512_shuffle_f32x4 ((_t01[0]), (_t01[8]), 0x88);
   rowA1   = _mm512_shuffle_f32x4 ((_t01[2]), (_t01[10]), 0x88);
   rowA2   = _mm512_shuffle_f32x4 ((_t01[4]), (_t01[12]), 0x88);
   rowA3   = _mm512_shuffle_f32x4 ((_t01[6]), (_t01[14]), 0x88);
   rowA4   = _mm512_shuffle_f32x4 ((_t01[0]), (_t01[8]), 0xDD);
   rowA5   = _mm512_shuffle_f32x4 ((_t01[2]), (_t01[10]), 0xDD);
   rowA6   = _mm512_shuffle_f32x4 ((_t01[4]), (_t01[12]), 0xDD);
   rowA7   = _mm512_shuffle_f32x4 ((_t01[6]), (_t01[14]), 0xDD);
   rowA8   = _mm512_shuffle_f32x4 ((_t01[1]), (_t01[9]), 0x88);
   rowA9   = _mm512_shuffle_f32x4 ((_t01[3]), (_t01[11]), 0x88);
   rowA10  = _mm512_shuffle_f32x4 ((_t01[5]), (_t01[13]), 0x88);
   rowA11  = _mm512_shuffle_f32x4 ((_t01[7]), (_t01[15]), 0x88);
   rowA12  = _mm512_shuffle_f32x4 ((_t01[1]), (_t01[9]), 0xDD);
   rowA13  = _mm512_shuffle_f32x4 ((_t01[3]), (_t01[11]), 0xDD);
   rowA14  = _mm512_shuffle_f32x4 ((_t01[5]), (_t01[13]), 0xDD);
   rowA15  = _mm512_shuffle_f32x4 ((_t01[7]), (_t01[15]), 0xDD);
